---
title: "코세라) 신경망 및 딥러닝 - 파이썬과 벡터화 - 넘파이를 사용한 파이썬 기초"
date: 2024-07-17T22:50:02+09:00
tags: ["neural network","구글 머신러닝 부트캠프"]
categories: ["neural network"]
author: "Jaejin Jang"
showToc: true
---

### Exercise 2 - basic_sigmoid
- 시그모이드 함수를 math 라이브러리를 이용하여 구현한 것입니다.
- 일반적으로 행열을 처리할 수 있는 np를 쓰는데, 그 반대의 경우(math)를 보여줌으로써 np를 강조하는건가 봐요.

```python
import math

def basic_sigmoid(x):
    s = 1/(1+math.exp(-x))
    return s
```

### Exercise 3 - sigmoid
- np를 이용해 구현합니다.

```python
def sigmoid(x):
    s = 1/(1+np.exp(-x))
    return s
```

### Exercise 4 - sigmoid_derivative

```python
def sigmoid(x):
    s = 1/(1+np.exp(-x)) 
    ds = s*(1-s)
    return ds
```

### Exercise 5 - image2vector
- reshape() 차원인자에 한개의 -1을 전달할 수 있습니다. **-1로 전달하면 나머지 차원인자로 부터 차원을 추론하여 동작합니다.**

```python
def image2vector(image):
    v = image.reshape(image.shape[0] * image.shape[1] * image.shape[2], 1)
    # v = image.reshape(-1, 1)
    # v = np.reshape(image, (image.shape[0] * image.shape[1] * image.shape[2], 1))
    return v
```

### Exercise 6 - normalize_rows

```python
def normalize_rows(x):
    x_norm = np.linalg.norm(x, axis=1, keepdims = True)
    x = np.divide(x, x_norm)
    return x
```

### Exercise 7 - softmax
- axis는 0과 1에 따라 행으로 동작(column-wise)할건지 열(row-wise)로 동작할것인지, keepdims는 브로드캐스팅 유무입니다

```python
def softmax(x):
    x_exp = np.exp(x)
    x_sum = np.sum(x_exp, axis=1, keepdims = True)
    s = np.divide(x_exp, x_sum)
    return s
```

### Exercise 8 - L1

```python
def L1(yhat, y):
    loss = np.sum(abs(np.subtract(yhat, y))) 
    return loss
```

### Exercise 9 - L2

```python
def L2(yhat, y):
    loss = np.sum(np.dot(np.subtract(yhat, y),np.subtract(yhat, y))) 
    return loss
```